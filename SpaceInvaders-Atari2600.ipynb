{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceInvaders-Atari2600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf     # Deep Learning library\n",
    "import numpy as np          # Linear algebra library\n",
    "import retro                # Environment library\n",
    "\n",
    "from skimage import transform        # Help us to preprocess the frames\n",
    "from skimage.color import rgb2gray   # Help us to grayscale our frames\n",
    "\n",
    "import matplotlib.pyplot as plt      # Display graphs\n",
    "%matplotlib inline\n",
    "from collections import deque        # Ordered collections with ends\n",
    "\n",
    "import random                        # Random numbers\n",
    "\n",
    "import warnings                      # This ignore all the warning messages that are normally printed\n",
    "                                     # during the training because of skimage\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.frame_preparation import preprocess_frame, stack_frames\n",
    "from src.exp_exp_tradeoff import predict_action\n",
    "from src.environment import create_environment, game_commands\n",
    "from src.change_action import action_to_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up our hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "state_size = [110, 84, 4]         # Our input is a stack of 4 frames hence 110x84x4 (Width, height, channels) \n",
    "action_size = 3                   # 3 possible actions\n",
    "learning_rate =  0.00025          # Alpha (aka learning rate)\n",
    "\n",
    "# Training hyperparameters\n",
    "total_episodes = 20               # Total episodes for training\n",
    "max_steps = 50000                 # Max possible steps in an episode\n",
    "batch_size = 3000                 # Batch size\n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1                 # Exploration probability at start\n",
    "explore_stop = 0.01               # Minimum exploration probability \n",
    "decay_rate = 0.00001              # Exponential decay rate for exploration prob\n",
    "\n",
    "# Q learning hyperparameters\n",
    "gamma_start = 1                   # Discounting rate\n",
    "gamma_decay_rate = 0.000000002\n",
    "# Memory hyperparameters\n",
    "pretrain_length = batch_size      # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 25600               # Number of experiences the Memory can keep\n",
    "\n",
    "# Preprocessing hyperparameters\n",
    "stack_size = 4                    # Number of frames stacked\n",
    "\n",
    "# MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = True\n",
    "\n",
    "# TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False\n",
    "\n",
    "# Do you want to use commands ?\n",
    "use_commands = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our frame is:  Box(210, 160, 3)\n",
      "\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "env, action_space, possible_actions, commands = create_environment(retro, 'SpaceInvaders-Atari2600', 3,\n",
    "                                                                   use_commands, game_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our Deep Q-learning Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our Deep Q-learning model:\n",
    "* We take a stack of 4 frames as input\n",
    "* It passes through 3 convnets\n",
    "* Then it is flattened\n",
    "* Finally it passes through 2 FC layers\n",
    "* It outputs a Q value for each action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - From /Users/Oleh/Downloads/deep-q-learning-master-2/src/agent.py:54: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING - From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING - From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING - From /Users/Oleh/Downloads/deep-q-learning-master-2/src/agent.py:99: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.agent import DQNetwork\n",
    "\n",
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Instantiate the DeepQNetwork\n",
    "DQNetwork = DQNetwork(state_size, action_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experience_replay import Memory\n",
    "stacked_frames = deque([np.zeros((110, 84), dtype=np.int) for i in range (4)], maxlen=4)\n",
    "\n",
    "# Create the experience replay object\n",
    "memory = Memory(memory_size)\n",
    "\n",
    "# Instantiate memory with random tuples\n",
    "memory.instantiate_memory(env, possible_actions, (8, -12, 4, -12), action_size,\n",
    "                          commands, stacked_frames, pretrain_length, use_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.summary.scalar(\"Loss\", DQNetwork.loss)\n",
    "\n",
    "write_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "if training == True:\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Setup TensorBoard Writer\n",
    "        writer = tf.summary.FileWriter(\"./graphs\", sess.graph)\n",
    "        \n",
    "        # Initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Initialize the decay rate (that will use to reduce epsilon) \n",
    "        decay_step = 0\n",
    "        \n",
    "        rewards_list = []\n",
    "        \n",
    "        for episode in range(total_episodes):\n",
    "            # Set step to 0\n",
    "            step = 0\n",
    "            \n",
    "            # Initialize the rewards of the episode\n",
    "            episode_rewards = []\n",
    "            \n",
    "            # Make a new episode and observe the first state\n",
    "            state = env.reset()\n",
    "            \n",
    "            # Remember that stack frame function also call our preprocess function.\n",
    "            state, stacked_frames = stack_frames(stacked_frames, state, True, (8, -12, 4, -12))\n",
    "            \n",
    "            while step < max_steps:\n",
    "                step += 1\n",
    "                \n",
    "                # Increase decay_step\n",
    "                decay_step +=1\n",
    "                \n",
    "                # Predict the action to take and take it\n",
    "                action, explore_probability, gamma = predict_action(sess, DQNetwork, explore_start, explore_stop, decay_rate, decay_step,\n",
    "                                                                    state, possible_actions, gamma_start, gamma_decay_rate, step)\n",
    "                \n",
    "                # Change from an action to command, of course if you need\n",
    "                if use_commands:\n",
    "                    command = action_to_command(action, action_size, commands)\n",
    "                else:\n",
    "                    command = action\n",
    "                \n",
    "                # Perform the action and get the next_state, reward, and done information\n",
    "                next_state, reward, done, _ = env.step(command)\n",
    "                \n",
    "                if episode_render:\n",
    "                    env.render()\n",
    "                \n",
    "                # Add the reward to total reward\n",
    "                episode_rewards.append(reward)\n",
    "                # If the game is finished\n",
    "                if done:\n",
    "                    # The episode ends so no next state\n",
    "                    next_state = np.zeros((110,84), dtype=np.int)\n",
    "                    \n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False, (8, -12, 4, -12))\n",
    "\n",
    "                    # Set step = max_steps to end the episode\n",
    "                    step = max_steps\n",
    "\n",
    "                    # Get the total reward of the episode\n",
    "                    total_reward = np.sum(episode_rewards)\n",
    "                    \n",
    "                    print('Episode: {}'.format(episode),\n",
    "                          'Total reward: {}'.format(total_reward),\n",
    "                          'Explore P: {:.4f}'.format(explore_probability),\n",
    "                          'Training Loss {:.4f}'.format(loss),\n",
    "                          'Gamma: {}'.format(gamma))\n",
    "\n",
    "                    rewards_list.append((episode, total_reward))\n",
    "\n",
    "                    # Store transition <st,at,rt+1,st+1> in memory D\n",
    "                    memory.add((state, action, reward, next_state, done))\n",
    "\n",
    "                else:\n",
    "                    # Stack the frame of the next_state\n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False, (8, -12, 4, -12))\n",
    "                \n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state, done))\n",
    "\n",
    "                    # st+1 is now our current state\n",
    "                    state = next_state\n",
    "                    \n",
    "                    \n",
    "            # LEARNING PART            \n",
    "            # Obtain random batch from memory\n",
    "            batch = memory.sample(step)\n",
    "                    \n",
    "            states_mb = np.array([each[0] for each in batch], ndmin=3)\n",
    "            actions_mb = np.array([each[1] for each in batch])\n",
    "            rewards_mb = np.array([each[2] for each in batch]) \n",
    "            next_states_mb = np.array([each[3] for each in batch], ndmin=3)\n",
    "            dones_mb = np.array([each[4] for each in batch])\n",
    "\n",
    "            target_Qs_batch = []\n",
    "\n",
    "            # Get Q values for next_state \n",
    "            Qs_next_state = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: next_states_mb})\n",
    "            # Set Q_target = r if the episode ends at s+1, otherwise set Q_target = r + gamma*maxQ(s', a')\n",
    "            for i in range(0, len(batch)):\n",
    "                terminal = dones_mb[i]\n",
    "\n",
    "                # If we are in a terminal state, only equals reward\n",
    "                if terminal:\n",
    "                    target_Qs_batch.append(rewards_mb[i])\n",
    "                        \n",
    "                else:\n",
    "                    target = rewards_mb[i] + gamma * np.max(Qs_next_state[i])\n",
    "                    target_Qs_batch.append(target)\n",
    "                        \n",
    "\n",
    "            targets_mb = np.array([each for each in target_Qs_batch])\n",
    "                \n",
    "            loss, _ = sess.run([DQNetwork.loss, DQNetwork.optimizer],\n",
    "                                    feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                               DQNetwork.target_Q: targets_mb,\n",
    "                                               DQNetwork.actions_: actions_mb})\n",
    "\n",
    "            # Clear our memory\n",
    "            memory.remove_all()\n",
    "            \n",
    "                # Write TF Summaries\n",
    "                #summary = sess.run(write_op)\n",
    "                #writer.add_summary(summary, episode)\n",
    "                #writer.flush()\n",
    "                    \n",
    "            # Save model\n",
    "            save_path = saver.save(sess, \"./space_models/model_\" + str(episode) + \"/model.ckpt\")\n",
    "            print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Watch our Agent play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./space_models/model_8/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Restoring parameters from ./space_models/model_8/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "EPISODE  0\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 1 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-051fe0003c35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/deep-q-learning-master-2/src/frame_preparation.py\u001b[0m in \u001b[0;36mstack_frames\u001b[0;34m(stacked_frames, state, is_new_episode, crop_size, stack_size)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Preprocess frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_new_episode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/deep-q-learning-master-2/src/frame_preparation.py\u001b[0m in \u001b[0;36mpreprocess_frame\u001b[0;34m(frame, crop_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mpreprocessed_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreprocessed_frame\u001b[0m   \u001b[0;31m# 110x84x1 frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[0;32m--> 149\u001b[0;31m                                     cval=cval, mode=ndi_mode)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# 2-dimensional interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0;32m--> 289\u001b[0;31m                               mode, cval, truncate)\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m     92\u001b[0m                          '(len(weights)-1) // 2')\n\u001b[1;32m     93\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[0m\u001b[1;32m     95\u001b[0m                           origin)\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    total_test_rewards = []\n",
    " \n",
    "    # Load the model\n",
    "    saver.restore(sess, \"./space_models/model_8/model.ckpt\")\n",
    "    \n",
    "    \n",
    "    for episode in range(5):\n",
    "        total_rewards = 0\n",
    "        \n",
    "        state = env.reset()\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True, (8, -12, 4, -12))\n",
    "        \n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "        \n",
    "        while True:\n",
    "            # Reshape the state\n",
    "            state = state.reshape((1, *state_size))\n",
    "            # Get action from Q-network \n",
    "            # Estimate the Qs values state\n",
    "            Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state})\n",
    "            \n",
    "            # Take the biggest Q value (= the best action)\n",
    "            choice = np.argmax(Qs)\n",
    "            action = possible_actions[choice]\n",
    "            \n",
    "            # Change from an action to command\n",
    "            command = action_to_command(action, action_size, commands)\n",
    "            \n",
    "            #Perform the action and get the next_state, reward, and done information\n",
    "            next_state, reward, done, _ = env.step(command)\n",
    "            env.render()\n",
    "            \n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                print (\"Score\", total_rewards)\n",
    "                total_test_rewards.append(total_rewards)\n",
    "                break\n",
    "                \n",
    "                \n",
    "            next_state, stacked_frames = stack_frames(stacked_frames, next_state, False, (8, -12, 4, -12))\n",
    "            state = next_state\n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
